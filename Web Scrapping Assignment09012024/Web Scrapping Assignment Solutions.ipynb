{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34063c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28258615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996e063",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c2eebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Headers\n",
      "0           Welcome to Wikipedia\n",
      "1  From today's featured article\n",
      "2               Did you know ...\n",
      "3                    In the news\n",
      "4                    On this day\n",
      "5     From today's featured list\n",
      "6       Today's featured picture\n",
      "7       Other areas of Wikipedia\n",
      "8    Wikipedia's sister projects\n",
      "9            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "def scrape_wikipedia_headers(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all header tags \n",
    "        header_texts =[]\n",
    "        for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "            header_texts.append(i.text)\n",
    "            \n",
    "        \n",
    "        # Create a DataFrame with the header texts\n",
    "        df = pd.DataFrame({'Headers': header_texts})\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Error: Unable to retrieve data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "headers_df = scrape_wikipedia_headers(url)\n",
    "print(headers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0842a4a",
   "metadata": {},
   "source": [
    "2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dba8c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Headers\n",
      "0         Shri Ram Nath Kovind14th President of India\n",
      "1        Shri Pranab Mukherjee13th President of India\n",
      "2   Smt Pratibha Devisingh Patil12th President of ...\n",
      "3       DR. A.P.J. Abdul Kalam11th President of India\n",
      "4         Shri K. R. Narayanan10th President of India\n",
      "5      Dr Shankar Dayal Sharma9th  President of India\n",
      "6           Shri R Venkataraman8th President of India\n",
      "7              Giani Zail Singh7th President of India\n",
      "8     Shri Neelam Sanjiva Reddy6th President of India\n",
      "9      Dr. Fakhruddin Ali Ahmed5th President of India\n",
      "10  Shri Varahagiri Venkata Giri4th President of I...\n",
      "11             Dr. Zakir Husain3rd President of India\n",
      "12  Dr. Sarvepalli Radhakrishnan2nd President of I...\n",
      "13          Dr. Rajendra Prasad1st President of India\n"
     ]
    }
   ],
   "source": [
    "def former_presidents_india(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all header tags \n",
    "        Presidents_list=[]\n",
    "        for i in soup.find_all('div',class_=\"desc-sec\"):\n",
    "            Presidents_list.append(i.text.strip().replace('\\n',''))\n",
    "            \n",
    "        \n",
    "        # Create a DataFrame with the header texts\n",
    "        df = pd.DataFrame({'Headers': Presidents_list})\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Error: Unable to retrieve data from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "url ='https://presidentofindia.nic.in/former-presidents'\n",
    "presidents = former_presidents_india(url)\n",
    "print(presidents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81009420",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b57a5",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d972c7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>34</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England</td>\n",
       "      <td>43</td>\n",
       "      <td>4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26</td>\n",
       "      <td>2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>29</td>\n",
       "      <td>2576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>27</td>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>28</td>\n",
       "      <td>2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>22</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>7</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team       Matches Points Rating\n",
       "0    1     Australia     34   4102\n",
       "1    2         India     32   3746\n",
       "2    3       England     43   4941\n",
       "3    4  South Africa     24   2536\n",
       "4    5   New Zealand     26   2471\n",
       "5    6      Pakistan     29   2576\n",
       "6    7     Sri Lanka     27   2123\n",
       "7    8   West Indies     28   2154\n",
       "8    9    Bangladesh     22   1131\n",
       "9   10      Zimbabwe      7    223"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.get('https://www.espncricinfo.com/rankings/content/page/211271.html')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "teams_data = []\n",
    "teams_table = soup.find('table', class_='StoryengineTable')\n",
    "#print(teams_table)\n",
    "for row in teams_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    team = columns[0].text.strip()\n",
    "    matches = columns[1].text.strip()\n",
    "    points = columns[2].text.strip()\n",
    "    rating = columns[3].text.strip()\n",
    "    teams_data.append({\n",
    "            'Team': team,\n",
    "            'Matches': matches,\n",
    "            'Points': points,\n",
    "            'Rating': rating\n",
    "        })\n",
    "           \n",
    "\n",
    "Teams_data=pd.DataFrame(teams_data)\n",
    "Teams_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ebb84",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "075365ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam\\n\\nPakistan</td>\n",
       "      <td>824</td>\n",
       "      <td>898 v West Indies, 10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shubman Gill\\n\\nIndia</td>\n",
       "      <td>801</td>\n",
       "      <td>847 v Australia, 24/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli\\n\\nIndia</td>\n",
       "      <td>768</td>\n",
       "      <td>911 v England, 12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma\\n\\nIndia</td>\n",
       "      <td>746</td>\n",
       "      <td>885 v Sri Lanka, 06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Warner\\n\\nAustralia</td>\n",
       "      <td>745</td>\n",
       "      <td>880 v Pakistan, 26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daryl Mitchell\\n\\nNew Zealand</td>\n",
       "      <td>728</td>\n",
       "      <td>750 v India, 15/11/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector\\n\\nIreland</td>\n",
       "      <td>723</td>\n",
       "      <td>729 v England, 23/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dawid Malan\\n\\nEngland</td>\n",
       "      <td>707</td>\n",
       "      <td>730 v Netherlands, 08/11/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rassie van der Dussen\\n\\nSouth Africa</td>\n",
       "      <td>701</td>\n",
       "      <td>796 v England, 19/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope\\n\\nWest Indies</td>\n",
       "      <td>699</td>\n",
       "      <td>808 v Bangladesh, 17/05/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Player Team                         Rating\n",
       "0                 Babar Azam\\n\\nPakistan  824  898 v West Indies, 10/06/2022\n",
       "1                  Shubman Gill\\n\\nIndia  801    847 v Australia, 24/09/2023\n",
       "2                   Virat Kohli\\n\\nIndia  768      911 v England, 12/07/2018\n",
       "3                  Rohit Sharma\\n\\nIndia  746    885 v Sri Lanka, 06/07/2019\n",
       "4              David Warner\\n\\nAustralia  745     880 v Pakistan, 26/01/2017\n",
       "5          Daryl Mitchell\\n\\nNew Zealand  728        750 v India, 15/11/2023\n",
       "6                Harry Tector\\n\\nIreland  723      729 v England, 23/09/2023\n",
       "7                 Dawid Malan\\n\\nEngland  707  730 v Netherlands, 08/11/2023\n",
       "8  Rassie van der Dussen\\n\\nSouth Africa  701      796 v England, 19/07/2022\n",
       "9               Shai Hope\\n\\nWest Indies  699   808 v Bangladesh, 17/05/2019"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://sports.ndtv.com/cricket/icc-rankings/odi-batting')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "batsmen_data = []\n",
    "batsmen_table = soup.find('table', class_=\"rnk_tbl\")\n",
    "for row in batsmen_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all(['td', 'th'])\n",
    "    player = columns[1].text.strip()\n",
    "    team = columns[2].text.strip()\n",
    "    rating = columns[3].text.strip()\n",
    "    batsmen_data.append({\n",
    "            'Player': player,\n",
    "            'Team': team,\n",
    "            'Rating': rating\n",
    "        })\n",
    "\n",
    "\n",
    "Batsmen_data=pd.DataFrame(batsmen_data)\n",
    "Batsmen_data    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c290b50",
   "metadata": {},
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a15253c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keshav Maharaj\\n\\nSouth Africa</td>\n",
       "      <td>716</td>\n",
       "      <td>741 v Australia, 16/11/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood\\n\\nAustralia</td>\n",
       "      <td>703</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj\\n\\nIndia</td>\n",
       "      <td>678</td>\n",
       "      <td>736 v New Zealand, 21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Zampa\\n\\nAustralia</td>\n",
       "      <td>675</td>\n",
       "      <td>695 v Bangladesh, 11/11/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashid Khan\\n\\nAfghanistan</td>\n",
       "      <td>667</td>\n",
       "      <td>806 v Pakistan, 21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah\\n\\nIndia</td>\n",
       "      <td>665</td>\n",
       "      <td>841 v West Indies, 01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shaheen Afridi\\n\\nPakistan</td>\n",
       "      <td>650</td>\n",
       "      <td>688 v West Indies, 10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mohammad Nabi\\n\\nAfghanistan</td>\n",
       "      <td>648</td>\n",
       "      <td>657 v Zimbabwe, 09/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kuldeep Yadav\\n\\nIndia</td>\n",
       "      <td>645</td>\n",
       "      <td>765 v New Zealand, 26/01/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trent Boult\\n\\nNew Zealand</td>\n",
       "      <td>643</td>\n",
       "      <td>775 v Australia, 11/09/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Player Team                         Rating\n",
       "0  Keshav Maharaj\\n\\nSouth Africa  716    741 v Australia, 16/11/2023\n",
       "1     Josh Hazlewood\\n\\nAustralia  703      733 v England, 26/01/2018\n",
       "2         Mohammed Siraj\\n\\nIndia  678  736 v New Zealand, 21/01/2023\n",
       "3         Adam Zampa\\n\\nAustralia  675   695 v Bangladesh, 11/11/2023\n",
       "4      Rashid Khan\\n\\nAfghanistan  667     806 v Pakistan, 21/09/2018\n",
       "5         Jasprit Bumrah\\n\\nIndia  665  841 v West Indies, 01/11/2018\n",
       "6      Shaheen Afridi\\n\\nPakistan  650  688 v West Indies, 10/06/2022\n",
       "7    Mohammad Nabi\\n\\nAfghanistan  648     657 v Zimbabwe, 09/06/2022\n",
       "8          Kuldeep Yadav\\n\\nIndia  645  765 v New Zealand, 26/01/2019\n",
       "9      Trent Boult\\n\\nNew Zealand  643    775 v Australia, 11/09/2022"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://sports.ndtv.com/cricket/icc-rankings/odi-bowling')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "bowler_data = []\n",
    "bowler_table = soup.find('table', class_=\"rnk_tbl\")\n",
    "for row in bowler_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all(['td', 'th'])\n",
    "    player = columns[1].text.strip()\n",
    "    team = columns[2].text.strip()\n",
    "    rating = columns[3].text.strip()\n",
    "    bowler_data.append({\n",
    "            'Player': player,\n",
    "            'Team': team,\n",
    "            'Rating': rating\n",
    "        })\n",
    "\n",
    "\n",
    "Bowler_data=pd.DataFrame(bowler_data)\n",
    "Bowler_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bda6a",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b4b76",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32d7469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia Women</td>\n",
       "      <td>24</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England Women</td>\n",
       "      <td>23</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa Women</td>\n",
       "      <td>25</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>New Zealand Women</td>\n",
       "      <td>25</td>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>India Women</td>\n",
       "      <td>21</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies Women</td>\n",
       "      <td>20</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh Women</td>\n",
       "      <td>17</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka Women</td>\n",
       "      <td>9</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan Women</td>\n",
       "      <td>27</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Thailand Women</td>\n",
       "      <td>11</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team             Matches Points Rating\n",
       "0    1     Australia Women     24   3950\n",
       "1    2       England Women     23   2991\n",
       "2    3  South Africa Women     25   2782\n",
       "3    4   New Zealand Women     25   2428\n",
       "4    5         India Women     21   2004\n",
       "5    6   West Indies Women     20   1768\n",
       "6    7    Bangladesh Women     17   1357\n",
       "7    8     Sri Lanka Women      9    714\n",
       "8    9      Pakistan Women     27   1852\n",
       "9   10      Thailand Women     11    753"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.get('https://www.espncricinfo.com/rankings/content/page/211271.html')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "teams_data=[]\n",
    "target_table = None\n",
    "for table in soup.find_all('table', class_='StoryengineTable'):\n",
    "    if '02 January 2024' in table.get_text():\n",
    "        target_table = table\n",
    "        break\n",
    "        \n",
    "#print(teams_table)\n",
    "if target_table:\n",
    "    for row in target_table.find_all('tr')[1:11]:\n",
    "        columns = row.find_all('td')\n",
    "        team = columns[0].text.strip()\n",
    "        matches = columns[1].text.strip()\n",
    "        points = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        teams_data.append({\n",
    "            'Team': team,\n",
    "            'Matches': matches,\n",
    "            'Points': points,\n",
    "            'Rating': rating\n",
    "        })\n",
    "        \n",
    "   \n",
    "           \n",
    "\n",
    "Teams_data=pd.DataFrame(teams_data)\n",
    "Teams_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3c5f7",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c097194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0)Natalie SciverENGLAND</td>\n",
       "      <td>ENGLAND</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1)Chamari AthapaththuSRI LANKA</td>\n",
       "      <td>SRI LANKA</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1)Laura WolvaardtSOUTH AFRICA</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2)Beth MooneyAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2)Ellyse PerryAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1)Smriti MandhanaINDIA</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1)Alyssa HealyAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0)Harmanpreet KaurINDIA</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0)Amelia KerrNEW ZEALAND</td>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0)Marizanne KappSOUTH AFRICA</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Player          Team Rating\n",
       "0         (0)Natalie SciverENGLAND       ENGLAND    807\n",
       "1  (1)Chamari AthapaththuSRI LANKA     SRI LANKA    736\n",
       "2   (1)Laura WolvaardtSOUTH AFRICA  SOUTH AFRICA    734\n",
       "3          (2)Beth MooneyAUSTRALIA     AUSTRALIA    731\n",
       "4         (2)Ellyse PerryAUSTRALIA     AUSTRALIA    720\n",
       "5          (1)Smriti MandhanaINDIA         INDIA    700\n",
       "6         (1)Alyssa HealyAUSTRALIA     AUSTRALIA    668\n",
       "7         (0)Harmanpreet KaurINDIA         INDIA    661\n",
       "8        (0)Amelia KerrNEW ZEALAND   NEW ZEALAND    642\n",
       "9    (0)Marizanne KappSOUTH AFRICA  SOUTH AFRICA    636"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://www.sportstiger.com/icc-rankings/women/batting')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "players_data = []\n",
    "players_table = soup.find('div', class_='rankings_table')\n",
    "\n",
    "for row in players_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    player = columns[1].text.strip()\n",
    "    team = columns[2].text.strip()\n",
    "    rating = columns[3].text.strip()\n",
    "\n",
    "    players_data.append({\n",
    "            'Player': player,\n",
    "            'Team': team,\n",
    "            'Rating': rating\n",
    "        })\n",
    "Players_data=pd.DataFrame(players_data)\n",
    "Players_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a6e7c",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c4d366fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0)Marizanne KappSOUTH AFRICA</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0)Ashleigh GardnerAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0)Natalie SciverENGLAND</td>\n",
       "      <td>ENGLAND</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0)Hayley MatthewsWEST INDIES</td>\n",
       "      <td>WEST INDIES</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0)Amelia KerrNEW ZEALAND</td>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0)Deepti SharmaINDIA</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0)Ellyse PerryAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2)Sophie DevineNEW ZEALAND</td>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1)Nida DarPAKISTAN</td>\n",
       "      <td>PAKISTAN</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1)Jess JonassenAUSTRALIA</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Player          Team Rating\n",
       "0  (0)Marizanne KappSOUTH AFRICA  SOUTH AFRICA    394\n",
       "1   (0)Ashleigh GardnerAUSTRALIA     AUSTRALIA    363\n",
       "2       (0)Natalie SciverENGLAND       ENGLAND    360\n",
       "3  (0)Hayley MatthewsWEST INDIES   WEST INDIES    358\n",
       "4      (0)Amelia KerrNEW ZEALAND   NEW ZEALAND    347\n",
       "5          (0)Deepti SharmaINDIA         INDIA    343\n",
       "6       (0)Ellyse PerryAUSTRALIA     AUSTRALIA    260\n",
       "7    (2)Sophie DevineNEW ZEALAND   NEW ZEALAND    245\n",
       "8            (1)Nida DarPAKISTAN      PAKISTAN    224\n",
       "9      (1)Jess JonassenAUSTRALIA     AUSTRALIA    218"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://www.sportstiger.com/icc-rankings/women/allrounder')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "AllRrounders_data = []\n",
    "AllRounders_table = soup.find('div', class_='rankings_table')\n",
    "\n",
    "for row in AllRounders_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    player = columns[1].text.strip()\n",
    "    team = columns[2].text.strip()\n",
    "    rating = columns[3].text.strip()\n",
    "\n",
    "    AllRrounders_data.append({\n",
    "            'Player': player,\n",
    "            'Team': team,\n",
    "            'Rating': rating\n",
    "        })\n",
    "AllRrounders_Data=pd.DataFrame(AllRrounders_data)\n",
    "AllRrounders_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c380993",
   "metadata": {},
   "source": [
    "5.Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\u0002i) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca81ac",
   "metadata": {},
   "source": [
    "i) Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e614f8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan markets are hitting multi-decade highs —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Americans are canceling trips that are thousan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline\n",
       "0  Japan markets are hitting multi-decade highs —...\n",
       "1  Americans are canceling trips that are thousan..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "headline =[]\n",
    "for i in soup.find_all('div',class_=\"SecondaryCard-headline\"):\n",
    "     headline.append(i.text)\n",
    "#print(headline)\n",
    "df = pd.DataFrame({'Headline': headline})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51968f",
   "metadata": {},
   "source": [
    "ii) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "27045856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>January 13, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time\n",
       "0         21 Min Ago\n",
       "1        3 Hours Ago\n",
       "2        5 Hours Ago\n",
       "3        5 Hours Ago\n",
       "4        6 Hours Ago\n",
       "5        6 Hours Ago\n",
       "6        7 Hours Ago\n",
       "7        7 Hours Ago\n",
       "8        7 Hours Ago\n",
       "9        7 Hours Ago\n",
       "10       9 Hours Ago\n",
       "11      10 Hours Ago\n",
       "12      10 Hours Ago\n",
       "13      12 Hours Ago\n",
       "14      15 Hours Ago\n",
       "15      15 Hours Ago\n",
       "16      15 Hours Ago\n",
       "17      15 Hours Ago\n",
       "18      15 Hours Ago\n",
       "19      16 Hours Ago\n",
       "20      16 Hours Ago\n",
       "21      16 Hours Ago\n",
       "22      16 Hours Ago\n",
       "23      16 Hours Ago\n",
       "24      17 Hours Ago\n",
       "25      17 Hours Ago\n",
       "26      18 Hours Ago\n",
       "27      18 Hours Ago\n",
       "28      18 Hours Ago\n",
       "29  January 13, 2024"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time =[]\n",
    "for i in soup.find_all('div',class_=\"LatestNews-container\"):\n",
    "    Time=i.find('time').text\n",
    "    time.append(Time)\n",
    "    \n",
    "#(time)\n",
    "df= pd.DataFrame({'Time': time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24605ee8",
   "metadata": {},
   "source": [
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6fae6dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European markets set to start new trading week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan markets are hitting multi-decade highs —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taiwan's new president will face a divided par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen Zers are leading the way in Singapore's on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNBC Daily Open: Big Bank earnings signal down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China stocks erase losses as central bank hold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Americans are canceling trips that are thousan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>House Republicans say they will re-subpoena Hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nikki Haley campaign site lacks policy platfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Defense Secretary Austin is 'actively involved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pro-Palestine protestors arrested for London S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Mean Girls' is the Queen Bee of the box offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>After big tech layoffs, Silicon Valley may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data shows that this is the key to successfull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How 27-year-old whose business brought in $1 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The 'holy grail' of longevity foods this docto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The No. 1 in-demand remote job companies are h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Barbara Corcoran: Why feeling like a fraud at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Please stop ignoring your flight attendants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hertz makes 'agile' decision to shift strategy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ramit Sethi: Common money belief could cost yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>This beach city is helping older adults achiev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Companies are betting on a promising class of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Link\n",
       "0   European markets set to start new trading week...\n",
       "1   Japan markets are hitting multi-decade highs —...\n",
       "2   Taiwan's new president will face a divided par...\n",
       "3   Gen Zers are leading the way in Singapore's on...\n",
       "4   CNBC Daily Open: Big Bank earnings signal down...\n",
       "5   China stocks erase losses as central bank hold...\n",
       "6                                                    \n",
       "7                                                    \n",
       "8   Americans are canceling trips that are thousan...\n",
       "9   House Republicans say they will re-subpoena Hu...\n",
       "10  Nikki Haley campaign site lacks policy platfor...\n",
       "11  Defense Secretary Austin is 'actively involved...\n",
       "12  Pro-Palestine protestors arrested for London S...\n",
       "13  'Mean Girls' is the Queen Bee of the box offic...\n",
       "14  After big tech layoffs, Silicon Valley may hav...\n",
       "15                                                   \n",
       "16  Data shows that this is the key to successfull...\n",
       "17  How 27-year-old whose business brought in $1 m...\n",
       "18  The 'holy grail' of longevity foods this docto...\n",
       "19  The No. 1 in-demand remote job companies are h...\n",
       "20  Barbara Corcoran: Why feeling like a fraud at ...\n",
       "21       Please stop ignoring your flight attendants \n",
       "22  Hertz makes 'agile' decision to shift strategy...\n",
       "23  Ramit Sethi: Common money belief could cost yo...\n",
       "24  This beach city is helping older adults achiev...\n",
       "25  Companies are betting on a promising class of ...\n",
       "26                                                   \n",
       "27                                                   \n",
       "28                                                   \n",
       "29                                                   "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link =[]\n",
    "for i in soup.find_all('div',class_=\"LatestNews-container\"):\n",
    "    Link=i.find('a').text\n",
    "    link.append(Link)\n",
    "    \n",
    "     \n",
    "        \n",
    "#print(link)\n",
    "df = pd.DataFrame({'Link': link})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6868db2",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame\u0002i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108daa1",
   "metadata": {},
   "source": [
    "i) Paper Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e126c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Paper title\n",
       "0  Artificial Intelligence"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "paper_title=[]\n",
    "for i in soup.find_all('header',class_=\"sc-orwwe2-2 iquSkg\"):\n",
    "    Paper_title=i.find('p').text\n",
    "    paper_title.append(Paper_title)\n",
    "    \n",
    "#print(paper_title)\n",
    "df = pd.DataFrame({'Paper title': paper_title})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643962ce",
   "metadata": {},
   "source": [
    "ii) Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3463cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tim Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Margaret A. Boden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Authors list\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...\n",
       "1                                         Tim Miller \n",
       "2                                  Margaret A. Boden \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...\n",
       "4                     Ilaria Tiddi, Stefan Schlobach \n",
       "5                     Henry Prakken, Giovanni Sartor \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland \n",
       "8                Wenhan Luo, Junliang Xing and 4 more\n",
       "9                      Saurabh Arora, Prashant Doshi \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...\n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...\n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...\n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...\n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more\n",
       "16                        Ron Kohavi, George H. John \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more\n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz \n",
       "19                            Luigia Carlucci Aiello \n",
       "20            Patrick Lin, Keith Abney, George Bekey \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more\n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...\n",
       "23             Markus Langer, Daniel Oster and 6 more"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Authors=[]\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    Authors.append(i.text)\n",
    "#print(Authors)        \n",
    "df = pd.DataFrame({'Authors list': Authors})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c611f",
   "metadata": {},
   "source": [
    "iii) Published Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c31eb76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>November 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>March 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>June 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>April 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>March 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>May 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>July 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Published date\n",
       "0     October 2021\n",
       "1    February 2019\n",
       "2      August 1998\n",
       "3    February 2015\n",
       "4     January 2022\n",
       "5     October 2015\n",
       "6      August 1999\n",
       "7   September 2021\n",
       "8       April 2021\n",
       "9      August 2021\n",
       "10   February 2021\n",
       "11      April 2023\n",
       "12   November 2021\n",
       "13      March 2023\n",
       "14        May 2021\n",
       "15      March 2020\n",
       "16   December 1997\n",
       "17       June 2017\n",
       "18       June 2021\n",
       "19       June 2016\n",
       "20      April 2011\n",
       "21      March 2023\n",
       "22        May 1998\n",
       "23       July 2021"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Published_Date=[]\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    Published_Date.append(i.text)\n",
    "#(Published_Date)       \n",
    "df = pd.DataFrame({'Published date': Published_Date})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d3de8",
   "metadata": {},
   "source": [
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "55dd1226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper url\n",
       "0                                    Reward is enough\n",
       "1   Explanation in artificial intelligence: Insigh...\n",
       "2              Creativity and artificial intelligence\n",
       "3   Conflict-based search for optimal multi-agent ...\n",
       "4   Knowledge graphs as tools for explainable mach...\n",
       "5   Law and logic: A review from an argumentation ...\n",
       "6   Between MDPs and semi-MDPs: A framework for te...\n",
       "7   Explaining individual predictions when feature...\n",
       "8       Multiple object tracking: A literature review\n",
       "9   A survey of inverse reinforcement learning: Ch...\n",
       "10  Evaluating XAI: A comparison of rule-based and...\n",
       "11  Explainable AI tools for legal reasoning about...\n",
       "12            Hard choices in artificial intelligence\n",
       "13  Assessing the communication gap between AI mod...\n",
       "14  Explaining black-box classifiers using post-ho...\n",
       "15  The Hanabi challenge: A new frontier for AI re...\n",
       "16              Wrappers for feature subset selection\n",
       "17  Artificial cognition for social human–robot in...\n",
       "18  A review of possible effects of cognitive bias...\n",
       "19  The multifaceted impact of Ada Lovelace in the...\n",
       "20  Robot ethics: Mapping the issues for a mechani...\n",
       "21          Reward (Mis)design for autonomous driving\n",
       "22  Planning and acting in partially observable st...\n",
       "23  What do we want from Explainable Artificial In..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_url=[]\n",
    "for i in soup.find_all('li',class_=\"sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs\"):\n",
    "    Paper_url=i.find('a').text\n",
    "    paper_url.append(Paper_url)\n",
    "    \n",
    "#print(paper_url)\n",
    "df= pd.DataFrame({'Paper url': paper_url})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf925477",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\u0002i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168578f",
   "metadata": {},
   "source": [
    "i) Restaurant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9f7f8375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park,Sector 51...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Restaurant name \n",
       "0      Castle BarbequeConnaught Place, Central Delhi\n",
       "1  Cafe KnoshThe Leela Ambience Convention Hotel,...\n",
       "2    India GrillHilton Garden Inn,Saket, South Delhi\n",
       "3  The Barbeque CompanyGardens Galleria,Sector 38...\n",
       "4  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...\n",
       "5  The Monarch - Bar Be Que VillageIndirapuram Ha...\n",
       "6  The Barbeque TimesM2K Corporate Park,Sector 51..."
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n",
    "Restaurant_name=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    Restaurant_name.append(i.text)\n",
    "#print(Restaurant_name)        \n",
    "df = pd.DataFrame({'Restaurant name ': Restaurant_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083835c",
   "metadata": {},
   "source": [
    "ii) Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9d35af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cuisine\n",
       "0       Chinese\n",
       "1       Italian\n",
       "2  North Indian\n",
       "3  North Indian\n",
       "4  North Indian\n",
       "5  North Indian\n",
       "6  North Indian"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cuisine=[]\n",
    "for i in soup.find_all('div',class_=\"detail-info\"):\n",
    "    cuisine=i.find('a').text\n",
    "    Cuisine.append(cuisine)\n",
    "#print(Cuisine)       \n",
    "df = pd.DataFrame({'Cuisine': Cuisine})\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595505ad",
   "metadata": {},
   "source": [
    "iii) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "37fe2b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Location \n",
      "0                     Connaught Place, Central Delhi\n",
      "1  The Leela Ambience Convention Hotel,Shahdara, ...\n",
      "2               Hilton Garden Inn,Saket, South Delhi\n",
      "3                 Gardens Galleria,Sector 38A, Noida\n",
      "4     Taurus Sarovar Portico,Mahipalpur, South Delhi\n",
      "5  Indirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
      "6              M2K Corporate Park,Sector 51, Gurgaon\n"
     ]
    }
   ],
   "source": [
    "Location=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "     Location.append(i.text)\n",
    "#print(Location)        \n",
    "df = pd.DataFrame({'Location ': Location})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74abd15f",
   "metadata": {},
   "source": [
    "iv) Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "93c27ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ratings\n",
      "0       4\n",
      "1     4.3\n",
      "2     3.9\n",
      "3     3.9\n",
      "4     3.7\n",
      "5     3.8\n",
      "6     4.1\n"
     ]
    }
   ],
   "source": [
    "Ratings=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#print(Image_url)       \n",
    "df = pd.DataFrame({'Ratings': Ratings})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dc6b9",
   "metadata": {},
   "source": [
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "999d4096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           image url\n",
      "0  https://im1.dineout.co.in/images/uploads/resta...\n",
      "1  https://im1.dineout.co.in/images/uploads/resta...\n",
      "2  https://im1.dineout.co.in/images/uploads/resta...\n",
      "3  https://im1.dineout.co.in/images/uploads/resta...\n",
      "4  https://im1.dineout.co.in/images/uploads/resta...\n",
      "5  https://im1.dineout.co.in/images/uploads/resta...\n",
      "6  https://im1.dineout.co.in/images/uploads/resta...\n"
     ]
    }
   ],
   "source": [
    "Image_url=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    Image_url.append(i['data-src'])\n",
    "    \n",
    "#print(Image_url)       \n",
    "df = pd.DataFrame({'image url': Image_url})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368a374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
